[
  {
    "id": "openai-community/gpt2",
    "downloads": 11503953,
    "likes": 3015,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "jax",
      "tflite",
      "rust",
      "onnx",
      "safetensors",
      "gpt2",
      "text-generation",
      "exbert",
      "en",
      "doi:10.57967/hf/0039",
      "license:mit",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen2.5-7B-Instruct",
    "downloads": 9466432,
    "likes": 871,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2309.00071",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-7B",
      "base_model:finetune:Qwen/Qwen2.5-7B",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model Qwen/Qwen2.5-7B-Instruct is not supported for task text-generation and provider together. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-0.6B",
    "downloads": 7313567,
    "likes": 783,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'fireworks-ai'. Available tasks: ['conversational']",
    "local_transformers_hint": true
  },
  {
    "id": "Gensyn/Qwen2.5-0.5B-Instruct",
    "downloads": 6512211,
    "likes": 28,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "rl-swarm",
      "gensyn",
      "conversational",
      "en",
      "base_model:Qwen/Qwen2.5-0.5B",
      "base_model:finetune:Qwen/Qwen2.5-0.5B",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-4B-Instruct-2507",
    "downloads": 5631733,
    "likes": 475,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'nscale'. Available tasks: ['conversational', 'text-to-image']",
    "local_transformers_hint": true
  },
  {
    "id": "meta-llama/Llama-3.1-8B-Instruct",
    "downloads": 5126476,
    "likes": 4935,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "base_model:meta-llama/Llama-3.1-8B",
      "base_model:finetune:meta-llama/Llama-3.1-8B",
      "license:llama3.1",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model meta-llama/Llama-3.1-8B-Instruct is not supported for task text-generation and provider novita. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "openai/gpt-oss-20b",
    "downloads": 5064222,
    "likes": 3925,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "autotrain_compatible",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'groq'. Available tasks: ['conversational']",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-Embedding-0.6B",
    "downloads": 5038951,
    "likes": 732,
    "tags": [
      "sentence-transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "transformers",
      "sentence-similarity",
      "feature-extraction",
      "text-embeddings-inference",
      "arxiv:2506.05176",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "feature-extraction",
    "inference_serverless_ok": false,
    "inference_error": "Model 'Qwen/Qwen3-Embedding-0.6B' doesn't support task 'text-generation'. Supported tasks: 'feature-extraction', got: 'text-generation'",
    "local_transformers_hint": true
  },
  {
    "id": "dphn/dolphin-2.9.1-yi-1.5-34b",
    "downloads": 4665728,
    "likes": 49,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "generated_from_trainer",
      "axolotl",
      "conversational",
      "dataset:cognitivecomputations/Dolphin-2.9",
      "dataset:teknium/OpenHermes-2.5",
      "dataset:m-a-p/CodeFeedback-Filtered-Instruction",
      "dataset:cognitivecomputations/dolphin-coder",
      "dataset:cognitivecomputations/samantha-data",
      "dataset:microsoft/orca-math-word-problems-200k",
      "dataset:Locutusque/function-calling-chatml",
      "dataset:internlm/Agent-FLAN",
      "base_model:01-ai/Yi-1.5-34B",
      "base_model:finetune:01-ai/Yi-1.5-34B",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen2.5-3B-Instruct",
    "downloads": 4456115,
    "likes": 326,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-3B",
      "base_model:finetune:Qwen/Qwen2.5-3B",
      "license:other",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-8B",
    "downloads": 4143687,
    "likes": 743,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-8B-Base",
      "base_model:finetune:Qwen/Qwen3-8B-Base",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'nscale'. Available tasks: ['conversational', 'text-to-image']",
    "local_transformers_hint": true
  },
  {
    "id": "facebook/opt-125m",
    "downloads": 4114309,
    "likes": 225,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "jax",
      "opt",
      "text-generation",
      "en",
      "arxiv:2205.01068",
      "arxiv:2005.14165",
      "license:other",
      "autotrain_compatible",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "openai/gpt-oss-120b",
    "downloads": 4052543,
    "likes": 4150,
    "tags": [
      "transformers",
      "safetensors",
      "gpt_oss",
      "text-generation",
      "vllm",
      "conversational",
      "arxiv:2508.10925",
      "license:apache-2.0",
      "autotrain_compatible",
      "endpoints_compatible",
      "8-bit",
      "mxfp4",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'groq'. Available tasks: ['conversational']",
    "local_transformers_hint": true
  },
  {
    "id": "trl-internal-testing/tiny-Qwen2ForCausalLM-2.5",
    "downloads": 3790080,
    "likes": 2,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "trl",
      "conversational",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "meta-llama/Llama-3.2-1B-Instruct",
    "downloads": 3671956,
    "likes": 1159,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model meta-llama/Llama-3.2-1B-Instruct is not supported for task text-generation and provider novita. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen2.5-1.5B-Instruct",
    "downloads": 3629125,
    "likes": 541,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-1.5B",
      "base_model:finetune:Qwen/Qwen2.5-1.5B",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model Qwen/Qwen2.5-1.5B-Instruct is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "downloads": 3119429,
    "likes": 1449,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "en",
      "dataset:cerebras/SlimPajama-627B",
      "dataset:bigcode/starcoderdata",
      "dataset:HuggingFaceH4/ultrachat_200k",
      "dataset:HuggingFaceH4/ultrafeedback_binarized",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "mistralai/Mistral-7B-Instruct-v0.2",
    "downloads": 3100416,
    "likes": 3014,
    "tags": [
      "transformers",
      "pytorch",
      "safetensors",
      "mistral",
      "text-generation",
      "finetuned",
      "mistral-common",
      "conversational",
      "arxiv:2310.06825",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model mistralai/Mistral-7B-Instruct-v0.2 is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
    "downloads": 2987594,
    "likes": 7,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "bigscience/bloomz-560m",
    "downloads": 2628650,
    "likes": 129,
    "tags": [
      "transformers",
      "pytorch",
      "tensorboard",
      "safetensors",
      "bloom",
      "text-generation",
      "ak",
      "ar",
      "as",
      "bm",
      "bn",
      "ca",
      "code",
      "en",
      "es",
      "eu",
      "fon",
      "fr",
      "gu",
      "hi",
      "id",
      "ig",
      "ki",
      "kn",
      "lg",
      "ln",
      "ml",
      "mr",
      "ne",
      "nso",
      "ny",
      "or",
      "pa",
      "pt",
      "rn",
      "rw",
      "sn",
      "st",
      "sw",
      "ta",
      "te",
      "tn",
      "ts",
      "tum",
      "tw",
      "ur",
      "vi",
      "wo",
      "xh",
      "yo",
      "zh",
      "zu",
      "dataset:bigscience/xP3",
      "arxiv:2211.01786",
      "license:bigscience-bloom-rail-1.0",
      "model-index",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "google/gemma-3-1b-it",
    "downloads": 2535378,
    "likes": 708,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "conversational",
      "arxiv:1905.07830",
      "arxiv:1905.10044",
      "arxiv:1911.11641",
      "arxiv:1904.09728",
      "arxiv:1705.03551",
      "arxiv:1911.01547",
      "arxiv:1907.10641",
      "arxiv:1903.00161",
      "arxiv:2009.03300",
      "arxiv:2304.06364",
      "arxiv:2103.03874",
      "arxiv:2110.14168",
      "arxiv:2311.12022",
      "arxiv:2108.07732",
      "arxiv:2107.03374",
      "arxiv:2210.03057",
      "arxiv:2106.03193",
      "arxiv:1910.11856",
      "arxiv:2502.12404",
      "arxiv:2502.21228",
      "arxiv:2404.16816",
      "arxiv:2104.12756",
      "arxiv:2311.16502",
      "arxiv:2203.10244",
      "arxiv:2404.12390",
      "arxiv:1810.12440",
      "arxiv:1908.02660",
      "arxiv:2312.11805",
      "base_model:google/gemma-3-1b-pt",
      "base_model:finetune:google/gemma-3-1b-pt",
      "license:gemma",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-4B",
    "downloads": 2154248,
    "likes": 446,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-4B-Base",
      "base_model:finetune:Qwen/Qwen3-4B-Base",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'fireworks-ai'. Available tasks: ['conversational']",
    "local_transformers_hint": true
  },
  {
    "id": "distilbert/distilgpt2",
    "downloads": 2098481,
    "likes": 592,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "jax",
      "tflite",
      "rust",
      "coreml",
      "safetensors",
      "gpt2",
      "text-generation",
      "exbert",
      "en",
      "dataset:openwebtext",
      "arxiv:1910.01108",
      "arxiv:2201.08542",
      "arxiv:2203.12574",
      "arxiv:1910.09700",
      "arxiv:1503.02531",
      "license:apache-2.0",
      "model-index",
      "co2_eq_emissions",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "meta-llama/Meta-Llama-3-8B",
    "downloads": 1995177,
    "likes": 6374,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "en",
      "license:llama3",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": true,
    "inference_error": null,
    "local_transformers_hint": true
  },
  {
    "id": "inference-net/Schematron-3B",
    "downloads": 1848551,
    "likes": 102,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "base_model:meta-llama/Llama-3.2-3B-Instruct",
      "base_model:finetune:meta-llama/Llama-3.2-3B-Instruct",
      "license:llama3.2",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "meta-llama/Llama-3.2-3B-Instruct",
    "downloads": 1834311,
    "likes": 1811,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model meta-llama/Llama-3.2-3B-Instruct is not supported for task text-generation and provider novita. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "meta-llama/Llama-3.2-1B",
    "downloads": 1789151,
    "likes": 2166,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "en",
      "de",
      "fr",
      "it",
      "pt",
      "hi",
      "es",
      "th",
      "arxiv:2204.05149",
      "arxiv:2405.16406",
      "license:llama3.2",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "downloads": 1786356,
    "likes": 1467,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "conversational",
      "arxiv:2501.12948",
      "license:mit",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B is not supported for task text-generation and provider novita. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "vikhyatk/moondream2",
    "downloads": 1717390,
    "likes": 1337,
    "tags": [
      "transformers",
      "safetensors",
      "moondream1",
      "text-generation",
      "image-text-to-text",
      "custom_code",
      "doi:10.57967/hf/6762",
      "license:apache-2.0",
      "autotrain_compatible",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "image-text-to-text",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "petals-team/StableBeluga2",
    "downloads": 1702093,
    "likes": 20,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "en",
      "dataset:conceptofmind/cot_submix_original",
      "dataset:conceptofmind/flan2021_submix_original",
      "dataset:conceptofmind/t0_submix_original",
      "dataset:conceptofmind/niv2_submix_original",
      "arxiv:2307.09288",
      "arxiv:2306.02707",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "openai-community/gpt2-large",
    "downloads": 1615911,
    "likes": 335,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "jax",
      "rust",
      "onnx",
      "safetensors",
      "gpt2",
      "text-generation",
      "en",
      "arxiv:1910.09700",
      "license:mit",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen2.5-0.5B-Instruct",
    "downloads": 1601789,
    "likes": 388,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-0.5B",
      "base_model:finetune:Qwen/Qwen2.5-0.5B",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen2.5-1.5B",
    "downloads": 1569953,
    "likes": 142,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "conversational",
      "en",
      "arxiv:2407.10671",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model Qwen/Qwen2.5-1.5B is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-Reranker-0.6B",
    "downloads": 1365534,
    "likes": 256,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "text-ranking",
      "arxiv:2506.05176",
      "base_model:Qwen/Qwen3-0.6B-Base",
      "base_model:finetune:Qwen/Qwen3-0.6B-Base",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-ranking",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
    "downloads": 1360986,
    "likes": 859,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3_next",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2404.06654",
      "arxiv:2505.09388",
      "arxiv:2501.15383",
      "license:apache-2.0",
      "autotrain_compatible",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model Qwen/Qwen3-Next-80B-A3B-Instruct is not supported for task text-generation and provider novita. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "microsoft/Phi-3-mini-4k-instruct",
    "downloads": 1301038,
    "likes": 1326,
    "tags": [
      "transformers",
      "safetensors",
      "phi3",
      "text-generation",
      "nlp",
      "code",
      "conversational",
      "custom_code",
      "en",
      "fr",
      "license:mit",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "sshleifer/tiny-gpt2",
    "downloads": 1292312,
    "likes": 32,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "jax",
      "gpt2",
      "text-generation",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-32B",
    "downloads": 1170954,
    "likes": 570,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2505.09388",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'groq'. Available tasks: ['conversational']",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen2.5-32B-Instruct-AWQ",
    "downloads": 1149614,
    "likes": 87,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "chat",
      "conversational",
      "en",
      "arxiv:2309.00071",
      "arxiv:2407.10671",
      "base_model:Qwen/Qwen2.5-32B-Instruct",
      "base_model:quantized:Qwen/Qwen2.5-32B-Instruct",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "4-bit",
      "awq",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "allenai/OLMo-2-0425-1B",
    "downloads": 1132665,
    "likes": 65,
    "tags": [
      "transformers",
      "safetensors",
      "olmo2",
      "text-generation",
      "en",
      "arxiv:2501.00656",
      "license:apache-2.0",
      "autotrain_compatible",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "kaitchup/Phi-3-mini-4k-instruct-gptq-4bit",
    "downloads": 1093525,
    "likes": 2,
    "tags": [
      "transformers",
      "safetensors",
      "phi3",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "4-bit",
      "gptq",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen2.5-7B",
    "downloads": 1093433,
    "likes": 242,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "conversational",
      "en",
      "arxiv:2407.10671",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model Qwen/Qwen2.5-7B is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "google-t5/t5-3b",
    "downloads": 1057543,
    "likes": 49,
    "tags": [
      "transformers",
      "pytorch",
      "tf",
      "safetensors",
      "t5",
      "text-generation",
      "summarization",
      "translation",
      "en",
      "fr",
      "ro",
      "de",
      "multilingual",
      "dataset:c4",
      "arxiv:1805.12471",
      "arxiv:1708.00055",
      "arxiv:1704.05426",
      "arxiv:1606.05250",
      "arxiv:1808.09121",
      "arxiv:1810.12885",
      "arxiv:1905.10044",
      "arxiv:1910.09700",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "translation",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "downloads": 1054896,
    "likes": 1383,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "conversational",
      "arxiv:2501.12948",
      "license:mit",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'nscale'. Available tasks: ['conversational', 'text-to-image']",
    "local_transformers_hint": true
  },
  {
    "id": "rednote-hilab/dots.ocr",
    "downloads": 1030133,
    "likes": 1120,
    "tags": [
      "dots_ocr",
      "safetensors",
      "text-generation",
      "image-to-text",
      "ocr",
      "document-parse",
      "layout",
      "table",
      "formula",
      "transformers",
      "custom_code",
      "image-text-to-text",
      "conversational",
      "en",
      "zh",
      "multilingual",
      "license:mit",
      "region:us"
    ],
    "pipeline_tag": "image-text-to-text",
    "inference_serverless_ok": false,
    "inference_error": "",
    "local_transformers_hint": true
  },
  {
    "id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "downloads": 1022103,
    "likes": 4280,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "facebook",
      "meta",
      "pytorch",
      "llama-3",
      "conversational",
      "en",
      "license:llama3",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model meta-llama/Meta-Llama-3-8B-Instruct is not supported for task text-generation and provider novita. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "downloads": 1018841,
    "likes": 731,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "arxiv:2501.12948",
      "license:mit",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model deepseek-ai/DeepSeek-R1-Distill-Llama-70B is not supported for task text-generation and provider novita. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-1.7B",
    "downloads": 972122,
    "likes": 320,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Model Qwen/Qwen3-1.7B is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
    "local_transformers_hint": true
  },
  {
    "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "downloads": 958747,
    "likes": 823,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "arxiv:2501.12948",
      "license:mit",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'nscale'. Available tasks: ['conversational', 'text-to-image']",
    "local_transformers_hint": true
  },
  {
    "id": "Qwen/Qwen3-14B",
    "downloads": 913992,
    "likes": 314,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "conversational",
      "arxiv:2309.00071",
      "arxiv:2505.09388",
      "base_model:Qwen/Qwen3-14B-Base",
      "base_model:finetune:Qwen/Qwen3-14B-Base",
      "license:apache-2.0",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "inference_serverless_ok": false,
    "inference_error": "Task 'text-generation' not supported for provider 'nscale'. Available tasks: ['conversational', 'text-to-image']",
    "local_transformers_hint": true
  }
]